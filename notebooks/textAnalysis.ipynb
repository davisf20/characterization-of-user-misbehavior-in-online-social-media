{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-06T12:01:03.974574500Z",
     "start_time": "2023-07-06T12:01:03.924317300Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (C:\\Users\\davis\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\sequence.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Sentiment Analysis\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msentita\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m calculate_polarity\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Emotion Analysis\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfeel_it\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EmotionClassifier\n",
      "File \u001B[1;32m~\\miniconda3\\lib\\site-packages\\sentita\\__init__.py:9\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mCreated on Thu Aug 30 15:04:00 2018\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m@author: gianc\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Bidirectional, Dense, Embedding, Input, Lambda, LSTM, Layer, Activation, Dropout, concatenate, Flatten, MaxPooling1D, AveragePooling1D, Conv1D\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msequence\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pad_sequences\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend \u001B[38;5;28;01mas\u001B[39;00m K\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (C:\\Users\\davis\\miniconda3\\lib\\site-packages\\keras\\preprocessing\\sequence.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sentiment Analysis\n",
    "from sentita import calculate_polarity\n",
    "\n",
    "# Emotion Analysis\n",
    "from feel_it import EmotionClassifier\n",
    "\n",
    "# Toxicity Analysis\n",
    "from detoxify import Detoxify\n",
    "\n",
    "import re\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\davis\\AppData\\Local\\Temp\\ipykernel_7044\\1447714495.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(\"../data/sample_tweets.csv\", #path/to/tweets_file\n"
     ]
    }
   ],
   "source": [
    "dateparse = lambda x: pd.to_datetime(x, format=\"%Y-%m-%d %H:%M:%S%z\")  # pd.datetime.strptime\n",
    "\n",
    "tweets = pd.read_csv(\"../data/sample_tweets.csv\", #path/to/tweets_file\n",
    "                     # nrows = 400000,\n",
    "                     parse_dates=['created_at'],\n",
    "                     converters={\"user_id\": str,\n",
    "                                 \"tweet_id\": str},\n",
    "                     date_parser=dateparse,\n",
    "                     lineterminator='\\n')\n",
    "\n",
    "newsguard_scores = pd.read_csv(\"../data/newsguard_scores.csv\", #path/to/newsguard_scores_file\n",
    "                              converters={\"name\": str},\n",
    "                              lineterminator='\\n')\n",
    "\n",
    "# Converti la colonna 'score' in float, convertendo i valori non validi in NaN\n",
    "newsguard_scores['score'] = pd.to_numeric(newsguard_scores['score'], errors='coerce')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T13:06:10.868731300Z",
     "start_time": "2023-07-03T13:05:03.665506500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tweets_copy = tweets.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T13:27:27.388114600Z",
     "start_time": "2023-07-03T13:27:26.581904400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Sostituisci i valori NaN con '' nelle colonne 'text', 'retweeted_text' e 'quoted_text'\n",
    "tweets_copy['text'] = tweets_copy['text'].fillna('')\n",
    "tweets_copy['retweeted_text'] = tweets_copy['retweeted_text'].fillna('')\n",
    "tweets_copy['quoted_text'] = tweets_copy['quoted_text'].fillna('')\n",
    "\n",
    "# Assicurati che tutti i valori nelle colonne 'text', 'retweeted_text' e 'quoted_text' siano stringhe\n",
    "tweets_copy['text'] = tweets_copy['text'].astype(str)\n",
    "tweets_copy['retweeted_text'] = tweets_copy['retweeted_text'].astype(str)\n",
    "tweets_copy['quoted_text'] = tweets_copy['quoted_text'].astype(str)\n",
    "\n",
    "# Crea tre dataframe separati per 'text', 'retweeted_text' e 'quoted_text'\n",
    "text_df = tweets_copy[['tweet_id', 'text']].rename(columns={'text': 'all_text'})\n",
    "retweeted_text_df = tweets_copy[['tweet_id', 'retweeted_text']].rename(columns={'retweeted_text': 'all_text'})\n",
    "quoted_text_df = tweets_copy[['tweet_id', 'quoted_text']].rename(columns={'quoted_text': 'all_text'})\n",
    "\n",
    "# Concatena i dataframe\n",
    "all_text_df = pd.concat([text_df, retweeted_text_df, quoted_text_df])\n",
    "\n",
    "# Elimina le righe con all_text vuoto o nan\n",
    "all_text_df = all_text_df[all_text_df['all_text'].notna() & (all_text_df['all_text'] != '')]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T13:29:31.402779Z",
     "start_time": "2023-07-03T13:29:24.137846200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SentITA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "for index, row in tqdm(all_text_df.iterrows(), total=all_text_df.shape[0]):\n",
    "    sentence = row['all_text']\n",
    "    results, polarities = calculate_polarity([sentence])\n",
    "    sentiment = {\n",
    "        'Positive': polarities[0][0],\n",
    "        'Negative': polarities[0][1]\n",
    "    }\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "all_text_df['Sentiment'] = sentiments\n",
    "\n",
    "all_text_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, row in all_text_df.iterrows():\n",
    "    sentiment = row['Sentiment']\n",
    "    positive_score = sentiment['Positive']\n",
    "    negative_score = sentiment['Negative']\n",
    "    print(f\"Positive score: {positive_score}, Negative score: {negative_score}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Emotion Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### FEEL-IT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "emotion_classifier = EmotionClassifier()\n",
    "\n",
    "emotions = []\n",
    "for index, row in tqdm(all_text_df.iterrows(), total=all_text_df.shape[0]):\n",
    "    sentence = row['all_text']\n",
    "    emotion = emotion_classifier.predict(sentence)\n",
    "    emotions.append(emotion)\n",
    "\n",
    "all_text_df['emotion'] = emotions\n",
    "\n",
    "all_text_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Toxicity Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Detoxify"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Detoxify('multilingual')\n",
    "\n",
    "toxicities = []\n",
    "for index, row in tqdm(all_text_df.iterrows(), total=all_text_df.shape[0]):\n",
    "    sentence = row['all_text']\n",
    "    toxicity = model.predict(sentence)\n",
    "    toxicities.append(toxicity)\n",
    "\n",
    "all_text_df['toxicity'] = toxicities\n",
    "\n",
    "all_text_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Misinformation Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                    tweet_id  \\\n0        1340466213240135682   \n1        1340466401111388162   \n2        1340466489401503749   \n3        1340466830633267205   \n4        1340466917975461893   \n...                      ...   \n4640199  1375753714338828289   \n4640200  1375753786413694978   \n4640201  1375753788640931840   \n4640202  1375753790788362240   \n4640203  1375753791585275906   \n\n                                                  all_text  polarity  \\\n0        @maxdantoni E questo è quello che dice il Brit...       0.0   \n1        🚫💉\\n\\n#vaccination #vaccinations   #vaccinatie...       0.0   \n2        Quanta confusione con i vaccini,ci sono gli ef...       0.0   \n3        Covid-20, datemi un vaccino nel giro di un qua...       0.0   \n4        Quando stava per arrivare il vaccino ma lui va...       0.0   \n...                                                    ...       ...   \n4640199  Questa risposta da sola, all'interno delle FAQ...       0.0   \n4640200  NOVO MENE DAS VACINAS BRASILEIRAS https://t.co...       0.0   \n4640201  \"Brusaferro\":\\nPerché in un'intervista al @Cor...       0.0   \n4640202  Draghi e Speranza motivano la scelta sulle scu...       0.0   \n4640203  14/03\\nil 49% degli uomini repubblicani non vu...       0.0   \n\n         subjectivity    neg    neu    pos  compound  \\\n0                 0.0  0.073  0.927  0.000   -0.4588   \n1                 0.0  0.000  1.000  0.000    0.0000   \n2                 0.0  0.000  1.000  0.000    0.0000   \n3                 0.0  0.000  1.000  0.000    0.0000   \n4                 0.0  0.000  1.000  0.000    0.0000   \n...               ...    ...    ...    ...       ...   \n4640199           0.0  0.000  1.000  0.000    0.0000   \n4640200           0.0  0.000  1.000  0.000    0.0000   \n4640201           0.0  0.000  0.936  0.064    0.3400   \n4640202           0.0  0.000  1.000  0.000    0.0000   \n4640203           0.0  0.000  1.000  0.000    0.0000   \n\n                                                      link domain name  score  \n0                                [https://t.co/XF1BegpbKd]   t.co  NaN    NaN  \n1                                [https://t.co/2DVh4RmwVX]   t.co  NaN    NaN  \n2                                                       []   None  NaN    NaN  \n3                                [https://t.co/u2egYIILPp]   t.co  NaN    NaN  \n4                                [https://t.co/G9lVkvCIC2]   t.co  NaN    NaN  \n...                                                    ...    ...  ...    ...  \n4640199  [https://t.co/luwO2GBCfc, https://t.co/30NbbTF...   t.co  NaN    NaN  \n4640200                          [https://t.co/5OihXD939x]   t.co  NaN    NaN  \n4640201                          [https://t.co/n4sfzBojMv]   t.co  NaN    NaN  \n4640202                                                 []   None  NaN    NaN  \n4640203                          [https://t.co/cTf34I58KC]   t.co  NaN    NaN  \n\n[4640204 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>all_text</th>\n      <th>polarity</th>\n      <th>subjectivity</th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n      <th>compound</th>\n      <th>link</th>\n      <th>domain</th>\n      <th>name</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1340466213240135682</td>\n      <td>@maxdantoni E questo è quello che dice il Brit...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.073</td>\n      <td>0.927</td>\n      <td>0.000</td>\n      <td>-0.4588</td>\n      <td>[https://t.co/XF1BegpbKd]</td>\n      <td>t.co</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1340466401111388162</td>\n      <td>🚫💉\\n\\n#vaccination #vaccinations   #vaccinatie...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>[https://t.co/2DVh4RmwVX]</td>\n      <td>t.co</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1340466489401503749</td>\n      <td>Quanta confusione con i vaccini,ci sono gli ef...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>[]</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1340466830633267205</td>\n      <td>Covid-20, datemi un vaccino nel giro di un qua...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>[https://t.co/u2egYIILPp]</td>\n      <td>t.co</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1340466917975461893</td>\n      <td>Quando stava per arrivare il vaccino ma lui va...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>[https://t.co/G9lVkvCIC2]</td>\n      <td>t.co</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4640199</th>\n      <td>1375753714338828289</td>\n      <td>Questa risposta da sola, all'interno delle FAQ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>[https://t.co/luwO2GBCfc, https://t.co/30NbbTF...</td>\n      <td>t.co</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4640200</th>\n      <td>1375753786413694978</td>\n      <td>NOVO MENE DAS VACINAS BRASILEIRAS https://t.co...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>[https://t.co/5OihXD939x]</td>\n      <td>t.co</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4640201</th>\n      <td>1375753788640931840</td>\n      <td>\"Brusaferro\":\\nPerché in un'intervista al @Cor...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.936</td>\n      <td>0.064</td>\n      <td>0.3400</td>\n      <td>[https://t.co/n4sfzBojMv]</td>\n      <td>t.co</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4640202</th>\n      <td>1375753790788362240</td>\n      <td>Draghi e Speranza motivano la scelta sulle scu...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>[]</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4640203</th>\n      <td>1375753791585275906</td>\n      <td>14/03\\nil 49% degli uomini repubblicani non vu...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>[https://t.co/cTf34I58KC]</td>\n      <td>t.co</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>4640204 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Funzione per estrarre domini dai link\n",
    "def extract_domain(link_list):\n",
    "    if link_list:  # Se la lista non è vuota\n",
    "        link = link_list[0]\n",
    "        parsed_uri = urllib.parse.urlparse(link)\n",
    "        domain = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "        return domain\n",
    "    else:  # Se la lista è vuota\n",
    "        return None\n",
    "\n",
    "# Estrai tutti i link dai tweet\n",
    "all_text_df['link'] = all_text_df['all_text'].apply(lambda x: re.findall(r'(https?://[^\\s]+)', x))\n",
    "\n",
    "# Estrai il dominio da ogni link\n",
    "all_text_df['domain'] = all_text_df['link'].apply(extract_domain)\n",
    "\n",
    "# Unisci i tweet con newsguard_score in base al dominio\n",
    "all_text_df = all_text_df.merge(newsguard_scores, left_on='domain', right_on='name', how='left')\n",
    "\n",
    "all_text_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-03T15:52:29.312151400Z",
     "start_time": "2023-07-03T15:52:16.338750500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
